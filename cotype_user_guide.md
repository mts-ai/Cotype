# Перечень терминов

- **Искусственный интеллект** – область компьютерных наук, занимающаяся созданием вычислительных систем, способных выполнять задачи, требующие человеческого интеллекта, такие как восприятие, рассуждение, обучение и решение проблем.
- **Машинное обучение** – раздел искусственного интеллекта, в котором вычислительные системы обучаются выполнять задачи, анализируя и обобщая данные. Обучение происходит без явного программирования специфических инструкций.
- **Генеративные модели** – типы искусственного интеллекта, способные создавать новый контент, включая тексты, изображения и музыку. Такие модели обучаются на больших объемах данных и затем генерируют новый контент, имитируя наблюдаемые данные.
- **Дообучение (Fine-tuning)** – процесс настройки предобученной модели под конкретную задачу путем дополнительного обучения на более мелком и специфическом наборе данных.
- **Нейронная сеть** – математическая модель, состоящая из взаимосвязанных искусственных нейронов, организованных в слои, предназначенная для выполнения задач машинного обучения и обработки данных.
- **Токен** – минимальная единица текста, например, слово или символ. Применяется в обработке естественного языка для анализа и генерации текста.

# Перечень сокращений

- **API (Application Programming Interface)** - набор правил и инструментов для взаимодействия программного обеспечения. API предоставляет возможность различным приложениям обмениваться данными и функциональностью.
- **JSON (JavaScript Object Notation)** – лёгкий формат обмена данными. Формат легко читается человеком и парсируется компьютером.

# 1 Введение

Настоящий документ представляет собой руководство пользователя (далее руководство) системы Cotype.
Руководство описывает:
- общее определение системы;
- функции системы;
- эксплуатацию системы через API-запросы;
- взаимодействие с системой через веб-интерфейс.

## 1.1 Краткое описание возможностей

Cotype — это большая языковая модель для генерации и редактирования текстов, суммирования и анализа информации. Cotype включает в себя также веб-приложение для ее запуска и использования.

> В каждую модель, предоставляемую нашим клиентам и партнерам, встроен уникальный водяной знак. Это необходимо для установления факта утечки модели от клиента или партнера. Просим вас ответственно относиться к обеспечению безопасности хранения модели.

В следующей таблице приведены основные функции Cotype.

**Таблица 1**. Функции системы.

| Функция  | Описание | 
|-------|-----|
|Суммаризация текста| Позволяет пользователям получать краткое и информативное содержание предоставленных текстовых материалов. Эта функция особенно полезна для быстрой обработки больших объемов информации. Она  позволяет пользователям оперативно получать основные идеи и выводы без необходимости читать полный текст.  |
|Извлечение информации из текстовых данных| Пользователи могут получать конкретные данные из предоставленных текстов и выводить их в требуемом виде. Функция  включает в себя идентификацию и извлечение важных фактов, числовых значений, дат, имен собственных и других значимых элементов текста. Это существенно облегчает процесс анализа и использования информации для различных бизнес-потребностей.  |
|Творческая генерация| Обеспечивает создание оригинального текстового контента, такого как статьи, диалоги или рассказы, на основе заданных параметров и требований пользователя. Это позволяет компаниям быстро генерировать уникальный контент для маркетинговых материалов, блогов, презентаций и других целей, снижая зависимость от ручного труда и ускоряя процесс создания качественного текста.  |
|Классификация текстовых данных| Cotype осуществляет систематизацию и организацию объектов, явлений или понятий по определенным критериям. Это позволяет пользователям структурировать информацию, облегчая ее поиск и анализ. Классификация может быть основана на различных параметрах, таких как темы, категории, приоритеты или другие специфические требования, что обеспечивает гибкость и точность в управлении текстовыми данными.  |
|Ролевой отыгрыш| Позволяет системе отвечать от лица заданного персонажа или представителя определенной профессии, ведя диалог в стиле, соответствующем требуемой специальности. Это обеспечивает более естественное и релевантное взаимодействие с пользователями, что особенно важно для задач, связанных с клиентской поддержкой, обучением и другими  областями, требующими специфической коммуникации. |
| Ведение диалога с пользователем на естественном языке в режиме чата | Обеспечивает интерактивное и динамичное общение, позволяя пользователям получать ответы на вопросы, выполнять команды и получать поддержку в реальном времени. Высокий уровень понимания и генерации естественного языка обеспечивает комфортное и интуитивно понятное взаимодействие, что способствует улучшению пользовательского опыта и повышению удовлетворенности клиентов. |
| Генерация идей на заданную тематику | Дает возможность получать новые и креативные идеи, основанные на заданных темах или проблемах. Это особенно полезно для задач, связанных с инновациями, разработкой продуктов, маркетинговыми кампаниями и другими областями, где необходим свежий и оригинальный подход для решения поставленных задач. |

## 1.2 Уровень подготовки пользователей

Пользователи Системы должны:
- уметь взаимодействовать с системой через REST-API, осуществляя http-запросы через специализированные инструменты. Например, с помощью Postman и curl. 
- знать json-формат данных, используемый в API системы. 

## 1.3 Перечень эксплуатационной документации, с которой необходимо ознакомиться пользователю

Для работы в Системе, пользователь должен ознакомиться с настоящим руководством.

# 2 Назначение и условия применения

Система предназначена для обработки, генерации и анализа текстовых данных на основе запроса пользователя, сформулированного на естественном языке в свободной форме. 

Пользователь может взаимодействовать с LLM Cotype:
- через REST-API, отправляя http-запросы и получая ответы от LLM.
- через чат-интерфейс - веб-приложение, предназначенное для взаимодействия с LLM через веб-интерфейс.

> Для чат-интерфейса используется open source решение "NextChat".

# 3 Справочник по API

Справочник по API предоставляет базовую информацию для работы с продуктом и сообщениями в системе. 

## 3.1 POST/v1/chat/completions

Основным методом для взаимодействия с моделью является метод `POST/v1/chat/completions`. Он предназначен для отправки списка сообщений в формате чата. На основе полученных входных данных, модель сгенерирует ответ на запрос пользователя. Метод может использоваться как для ведения диалогов, состоящих из нескольких последовательных сообщений, так и для выполнения задач, требующих однократного обращения без продолжительного разговора.

**Тип запроса**: `POST`<br>
**Запрос**: [http://IP_Address/v1/chat/completions](http://IP_Address/v1/chat/completions)<br>
Где "IP_Address" необходимо заменить на IP-адрес вашей машины, если модель развёрнута внутри вашего контура. Если вы обращаетесь к демо-стенду внутри контура МТС ИИ, то адрес стенда будет передан вам отдельно.<br>
Например: [http://1.1.1.1:8000/v1/chat/completions](http://1.1.1.1:8000/v1/chat/completions)

**Таблица 2.** Параметры запроса `POST/v1/chat/completions`

| Имя | Тип данных | <div style="width:230px">Значение</div> | <div style="width:130px">Значение</div>  |
|-------|-----|----------|-----|
|messages (обязательный)| string | Текстовый ответ | Одно сообщение или список из нескольких сообщений в формате чата, на основе которых, модель должна сгенерировать ответ. |
|model (обязательный)| string | ID | ID модели, к которой вы обращаетесь. Вы можете узнать список доступных вам  моделей через запрос `GET/v1/models`. Подробнее в  разделе [3.2 - GET/v1/models](##32-GET/v1/models). |
|temperature| float | Диапазон температуры — от 0 до 2. Рекомендованное значение: 0.5 | Более низкие значения температуры приводят к более последовательным результатам (например, 0.2), в то время как более высокие значения генерируют более разнообразные и творческие результаты (например, 1.0).  |
|top_p| integer | Диапазон — от 0 до 1. | Чем ниже значение атрибута, тем более популярные и часто встречающиеся токены модель будет использовать для формирования ответа. <br> Рекомендуем изменять или этот атрибут, или temperature, но не оба сразу. |
|max_tokens| integer | Натуральное число, больше 0. |Максимальное количество токенов, которые могут быть сгенерированы в ответ на запрос пользователя. Это позволяет регулировать длину ответа. |
|n| integer | Натуральное число больше 0. По умолчанию: 1.  |Количество ответов, которые модель сгенерирует. |
|stream| boolean | True/False. По умолчанию: false. |Если установить значение true, ответ модели будет возвращаться не целиком сразу, а итеративно, по мере его формирования моделью. |
|stream_options| object or null  |  <code> "stream": true,<br>&nbsp;&nbsp;"stream_options":{<br>&nbsp;&nbsp;&nbsp;&nbsp;"include_usage": true<br>&nbsp;&nbsp;} </code> |Параметры для потокового ответа. Устанавливайте только при установке `stream: true`.  |
|&nbsp;&nbsp; include_usage| boolean  | <code> "usage": {<br>&nbsp;&nbsp; "prompt_tokens": 61,<br>&nbsp;&nbsp; "total_tokens": 446,<br>&nbsp;&nbsp; "completion_tokens": 385<br> } </code> |Если установлен в true,  то будет добавлен новый информационный фрагмент перед последним фрагментом `[DONE]`. Поле `usage` в этом фрагменте показывает статистику использования токенов для всего запроса, а поле `choices` всегда будет пустым массивом. |
|frequency_penalty| integer | Натуральное число от -2 до 2. |Штраф за частоту — число между -2.0 и 2.0. Положительные значения штрафуют новые токены, на основе их текущей частоты в тексте, снижая вероятность того, что модель повторит одну и ту же строку. |
|presence_penalty| integer | Натуральное число от -2 до 2. |Положительные значения накладывают штраф на новые токены в зависимости от того, появляются ли они в тексте до сих пор, увеличивая вероятность того, что модель будет говорить о новых темах. |
|logit_bias | map | По умолчанию: null |Позволяет изменять  вероятность появления указанных токенов в генерации. Принимает объект JSON, который сопоставляет токены (указанные по их идентификатору токена в токенизаторе) со связанным значением отклонения от -100 до 100. `logit_bias` позволяет запретить модели использовать некоторые ID токенов. Чем ближе значение параметра к -100, тем больше вероятность, что токен будет заблокирован моделью.  Чем ближе значение параметра к + 100, тем больше вероятность что токен будет использован моделью. |
|logprobs | boolean or null | По умолчанию: false |Задает возвращать ли  логарифмические вероятности выходных токенов или нет. Если true, возвращает логарифмические вероятности  каждого выходного токена, возвращенного в содержимом сообщения. |
|top_logprobs | integer or null | |Целое число от 0 до 20, регулирующее количество наиболее вероятных токенов с их логарифмическими вероятностями, которые будут возвращены для каждого генерируемого токена. Если используется этот параметр, то `logprobs` должен быть установлен в значение true. |
|stop | string/array/null | |Список строк, после которых останавливается генерация. Эти строки не будут включены в ответ.  |
|parallel_tool_calls| boolean | По умолчанию: true |Определяет следует ли включать параллельный вызов функций/тулов. |
|tool_choice | string |  |Определяет как модель выбирает tools. Значения - **auto**, **none**, **required**, или задайте функцию. |
|tools | array|  |Список функций (тулов) с описаниями и аргументами, среди которых модель может выбрать необходимые тулы и извлечь значения аргументов из промпта для использования приложением. |
|&nbsp;&nbsp;function | object|  |Вызываемая функция. |
|&nbsp;&nbsp;&nbsp;&nbsp; description | string |  |Описание функции, включая инструкцию, когда и как ее вызвать. |
|&nbsp;&nbsp;&nbsp;&nbsp; name | string |  |Название функции. |
|&nbsp;&nbsp;&nbsp;&nbsp; parameters | object |  |Параметры функции в json. |
|&nbsp;&nbsp;&nbsp;&nbsp; strict | boolean or null  |  |Задает следует ли включать строгое соблюдение схемы при генерации вызова функции. Если установлено  значение **true**, модель будет точно соответствовать схеме, определенной в поле `parameters`. Если значение `strict` равно **true**,  поддерживается только подмножество схем JSON. |
|&nbsp;&nbsp;type  | string|  |tool тип, например функция. |
|user | string|  |Уникальный идентификатор, представляющий вашего конечного пользователя, который может помочь отслеживать и обнаруживать злоупотребления. |

### 3.1.1 Использование запроса POST/v1/chat/completions

1. Укажите **Bearer Token**.<br> При активной однотокеновой авторизации токен одинаковый у всех пользователей. При пользовательской авторизации выдаются индивидуальные токены.
2. Заполните тело запроса. 

